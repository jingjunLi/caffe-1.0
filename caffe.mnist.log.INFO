Log file created at: 2017/06/09 05:04:32
Running on machine: DL
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0609 05:04:32.595582 30564 caffe.cpp:218] Using GPUs 0
I0609 05:04:32.729245 30564 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0609 05:04:34.355242 30564 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I0609 05:04:34.361703 30564 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0609 05:04:34.366521 30564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0609 05:04:34.366545 30564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0609 05:04:34.366674 30564 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0609 05:04:34.366905 30564 layer_factory.hpp:77] Creating layer mnist
I0609 05:04:34.391477 30564 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I0609 05:04:34.395364 30564 net.cpp:84] Creating Layer mnist
I0609 05:04:34.395398 30564 net.cpp:380] mnist -> data
I0609 05:04:34.395439 30564 net.cpp:380] mnist -> label
I0609 05:04:34.397351 30564 data_layer.cpp:45] output data size: 64,1,28,28
I0609 05:04:34.400795 30564 net.cpp:122] Setting up mnist
I0609 05:04:34.400820 30564 net.cpp:129] Top shape: 64 1 28 28 (50176)
I0609 05:04:34.400826 30564 net.cpp:129] Top shape: 64 (64)
I0609 05:04:34.400830 30564 net.cpp:137] Memory required for data: 200960
I0609 05:04:34.400841 30564 layer_factory.hpp:77] Creating layer conv1
I0609 05:04:34.400874 30564 net.cpp:84] Creating Layer conv1
I0609 05:04:34.400885 30564 net.cpp:406] conv1 <- data
I0609 05:04:34.400908 30564 net.cpp:380] conv1 -> conv1
I0609 05:04:35.871146 30564 net.cpp:122] Setting up conv1
I0609 05:04:35.871184 30564 net.cpp:129] Top shape: 64 20 24 24 (737280)
I0609 05:04:35.871188 30564 net.cpp:137] Memory required for data: 3150080
I0609 05:04:35.871219 30564 layer_factory.hpp:77] Creating layer pool1
I0609 05:04:35.871239 30564 net.cpp:84] Creating Layer pool1
I0609 05:04:35.871279 30564 net.cpp:406] pool1 <- conv1
I0609 05:04:35.871289 30564 net.cpp:380] pool1 -> pool1
I0609 05:04:35.871368 30564 net.cpp:122] Setting up pool1
I0609 05:04:35.871379 30564 net.cpp:129] Top shape: 64 20 12 12 (184320)
I0609 05:04:35.871383 30564 net.cpp:137] Memory required for data: 3887360
I0609 05:04:35.871387 30564 layer_factory.hpp:77] Creating layer conv2
I0609 05:04:35.871400 30564 net.cpp:84] Creating Layer conv2
I0609 05:04:35.871403 30564 net.cpp:406] conv2 <- pool1
I0609 05:04:35.871409 30564 net.cpp:380] conv2 -> conv2
I0609 05:04:35.876983 30564 net.cpp:122] Setting up conv2
I0609 05:04:35.877002 30564 net.cpp:129] Top shape: 64 50 8 8 (204800)
I0609 05:04:35.877007 30564 net.cpp:137] Memory required for data: 4706560
I0609 05:04:35.877020 30564 layer_factory.hpp:77] Creating layer pool2
I0609 05:04:35.877029 30564 net.cpp:84] Creating Layer pool2
I0609 05:04:35.877033 30564 net.cpp:406] pool2 <- conv2
I0609 05:04:35.877041 30564 net.cpp:380] pool2 -> pool2
I0609 05:04:35.877099 30564 net.cpp:122] Setting up pool2
I0609 05:04:35.877110 30564 net.cpp:129] Top shape: 64 50 4 4 (51200)
I0609 05:04:35.877116 30564 net.cpp:137] Memory required for data: 4911360
I0609 05:04:35.877120 30564 layer_factory.hpp:77] Creating layer ip1
I0609 05:04:35.877132 30564 net.cpp:84] Creating Layer ip1
I0609 05:04:35.877138 30564 net.cpp:406] ip1 <- pool2
I0609 05:04:35.877146 30564 net.cpp:380] ip1 -> ip1
I0609 05:04:35.880759 30564 net.cpp:122] Setting up ip1
I0609 05:04:35.880775 30564 net.cpp:129] Top shape: 64 500 (32000)
I0609 05:04:35.880779 30564 net.cpp:137] Memory required for data: 5039360
I0609 05:04:35.880789 30564 layer_factory.hpp:77] Creating layer relu1
I0609 05:04:35.880798 30564 net.cpp:84] Creating Layer relu1
I0609 05:04:35.880802 30564 net.cpp:406] relu1 <- ip1
I0609 05:04:35.880807 30564 net.cpp:367] relu1 -> ip1 (in-place)
I0609 05:04:35.881016 30564 net.cpp:122] Setting up relu1
I0609 05:04:35.881031 30564 net.cpp:129] Top shape: 64 500 (32000)
I0609 05:04:35.881034 30564 net.cpp:137] Memory required for data: 5167360
I0609 05:04:35.881038 30564 layer_factory.hpp:77] Creating layer ip2
I0609 05:04:35.881047 30564 net.cpp:84] Creating Layer ip2
I0609 05:04:35.881049 30564 net.cpp:406] ip2 <- ip1
I0609 05:04:35.881058 30564 net.cpp:380] ip2 -> ip2
I0609 05:04:35.882567 30564 net.cpp:122] Setting up ip2
I0609 05:04:35.882586 30564 net.cpp:129] Top shape: 64 10 (640)
I0609 05:04:35.882588 30564 net.cpp:137] Memory required for data: 5169920
I0609 05:04:35.882594 30564 layer_factory.hpp:77] Creating layer loss
I0609 05:04:35.882603 30564 net.cpp:84] Creating Layer loss
I0609 05:04:35.882606 30564 net.cpp:406] loss <- ip2
I0609 05:04:35.882611 30564 net.cpp:406] loss <- label
I0609 05:04:35.882622 30564 net.cpp:380] loss -> loss
I0609 05:04:35.882640 30564 layer_factory.hpp:77] Creating layer loss
I0609 05:04:35.883431 30564 net.cpp:122] Setting up loss
I0609 05:04:35.883448 30564 net.cpp:129] Top shape: (1)
I0609 05:04:35.883451 30564 net.cpp:132]     with loss weight 1
I0609 05:04:35.883479 30564 net.cpp:137] Memory required for data: 5169924
I0609 05:04:35.883486 30564 net.cpp:198] loss needs backward computation.
I0609 05:04:35.883496 30564 net.cpp:198] ip2 needs backward computation.
I0609 05:04:35.883499 30564 net.cpp:198] relu1 needs backward computation.
I0609 05:04:35.883505 30564 net.cpp:198] ip1 needs backward computation.
I0609 05:04:35.883508 30564 net.cpp:198] pool2 needs backward computation.
I0609 05:04:35.883512 30564 net.cpp:198] conv2 needs backward computation.
I0609 05:04:35.883519 30564 net.cpp:198] pool1 needs backward computation.
I0609 05:04:35.883524 30564 net.cpp:198] conv1 needs backward computation.
I0609 05:04:35.883528 30564 net.cpp:200] mnist does not need backward computation.
I0609 05:04:35.883532 30564 net.cpp:242] This network produces output loss
I0609 05:04:35.883543 30564 net.cpp:255] Network initialization done.
I0609 05:04:35.883750 30564 solver.cpp:172] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0609 05:04:35.883797 30564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0609 05:04:35.883893 30564 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0609 05:04:35.884152 30564 layer_factory.hpp:77] Creating layer mnist
I0609 05:04:35.901814 30564 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I0609 05:04:35.907203 30564 net.cpp:84] Creating Layer mnist
I0609 05:04:35.907238 30564 net.cpp:380] mnist -> data
I0609 05:04:35.907250 30564 net.cpp:380] mnist -> label
I0609 05:04:35.907353 30564 data_layer.cpp:45] output data size: 100,1,28,28
I0609 05:04:35.909796 30564 net.cpp:122] Setting up mnist
I0609 05:04:35.909814 30564 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0609 05:04:35.909819 30564 net.cpp:129] Top shape: 100 (100)
I0609 05:04:35.909822 30564 net.cpp:137] Memory required for data: 314000
I0609 05:04:35.909826 30564 layer_factory.hpp:77] Creating layer label_mnist_1_split
I0609 05:04:35.909921 30564 net.cpp:84] Creating Layer label_mnist_1_split
I0609 05:04:35.909957 30564 net.cpp:406] label_mnist_1_split <- label
I0609 05:04:35.909984 30564 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0609 05:04:35.910017 30564 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0609 05:04:35.910295 30564 net.cpp:122] Setting up label_mnist_1_split
I0609 05:04:35.910315 30564 net.cpp:129] Top shape: 100 (100)
I0609 05:04:35.910323 30564 net.cpp:129] Top shape: 100 (100)
I0609 05:04:35.910329 30564 net.cpp:137] Memory required for data: 314800
I0609 05:04:35.910337 30564 layer_factory.hpp:77] Creating layer conv1
I0609 05:04:35.910370 30564 net.cpp:84] Creating Layer conv1
I0609 05:04:35.910382 30564 net.cpp:406] conv1 <- data
I0609 05:04:35.910401 30564 net.cpp:380] conv1 -> conv1
I0609 05:04:35.912559 30564 net.cpp:122] Setting up conv1
I0609 05:04:35.912597 30564 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I0609 05:04:35.912611 30564 net.cpp:137] Memory required for data: 4922800
I0609 05:04:35.912634 30564 layer_factory.hpp:77] Creating layer pool1
I0609 05:04:35.912689 30564 net.cpp:84] Creating Layer pool1
I0609 05:04:35.912703 30564 net.cpp:406] pool1 <- conv1
I0609 05:04:35.912724 30564 net.cpp:380] pool1 -> pool1
I0609 05:04:35.912820 30564 net.cpp:122] Setting up pool1
I0609 05:04:35.912842 30564 net.cpp:129] Top shape: 100 20 12 12 (288000)
I0609 05:04:35.912852 30564 net.cpp:137] Memory required for data: 6074800
I0609 05:04:35.912861 30564 layer_factory.hpp:77] Creating layer conv2
I0609 05:04:35.912888 30564 net.cpp:84] Creating Layer conv2
I0609 05:04:35.912897 30564 net.cpp:406] conv2 <- pool1
I0609 05:04:35.912912 30564 net.cpp:380] conv2 -> conv2
I0609 05:04:35.916321 30564 net.cpp:122] Setting up conv2
I0609 05:04:35.916352 30564 net.cpp:129] Top shape: 100 50 8 8 (320000)
I0609 05:04:35.916363 30564 net.cpp:137] Memory required for data: 7354800
I0609 05:04:35.916405 30564 layer_factory.hpp:77] Creating layer pool2
I0609 05:04:35.916425 30564 net.cpp:84] Creating Layer pool2
I0609 05:04:35.916436 30564 net.cpp:406] pool2 <- conv2
I0609 05:04:35.916452 30564 net.cpp:380] pool2 -> pool2
I0609 05:04:35.916550 30564 net.cpp:122] Setting up pool2
I0609 05:04:35.916566 30564 net.cpp:129] Top shape: 100 50 4 4 (80000)
I0609 05:04:35.916576 30564 net.cpp:137] Memory required for data: 7674800
I0609 05:04:35.916585 30564 layer_factory.hpp:77] Creating layer ip1
I0609 05:04:35.916609 30564 net.cpp:84] Creating Layer ip1
I0609 05:04:35.916618 30564 net.cpp:406] ip1 <- pool2
I0609 05:04:35.916632 30564 net.cpp:380] ip1 -> ip1
I0609 05:04:35.924355 30564 net.cpp:122] Setting up ip1
I0609 05:04:35.924397 30564 net.cpp:129] Top shape: 100 500 (50000)
I0609 05:04:35.924407 30564 net.cpp:137] Memory required for data: 7874800
I0609 05:04:35.924430 30564 layer_factory.hpp:77] Creating layer relu1
I0609 05:04:35.924448 30564 net.cpp:84] Creating Layer relu1
I0609 05:04:35.924466 30564 net.cpp:406] relu1 <- ip1
I0609 05:04:35.924480 30564 net.cpp:367] relu1 -> ip1 (in-place)
I0609 05:04:35.925952 30564 net.cpp:122] Setting up relu1
I0609 05:04:35.925981 30564 net.cpp:129] Top shape: 100 500 (50000)
I0609 05:04:35.925989 30564 net.cpp:137] Memory required for data: 8074800
I0609 05:04:35.925999 30564 layer_factory.hpp:77] Creating layer ip2
I0609 05:04:35.926028 30564 net.cpp:84] Creating Layer ip2
I0609 05:04:35.926038 30564 net.cpp:406] ip2 <- ip1
I0609 05:04:35.926055 30564 net.cpp:380] ip2 -> ip2
I0609 05:04:35.926388 30564 net.cpp:122] Setting up ip2
I0609 05:04:35.926403 30564 net.cpp:129] Top shape: 100 10 (1000)
I0609 05:04:35.926412 30564 net.cpp:137] Memory required for data: 8078800
I0609 05:04:35.926427 30564 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0609 05:04:35.926443 30564 net.cpp:84] Creating Layer ip2_ip2_0_split
I0609 05:04:35.926453 30564 net.cpp:406] ip2_ip2_0_split <- ip2
I0609 05:04:35.926476 30564 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0609 05:04:35.926492 30564 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0609 05:04:35.926573 30564 net.cpp:122] Setting up ip2_ip2_0_split
I0609 05:04:35.926589 30564 net.cpp:129] Top shape: 100 10 (1000)
I0609 05:04:35.926599 30564 net.cpp:129] Top shape: 100 10 (1000)
I0609 05:04:35.926607 30564 net.cpp:137] Memory required for data: 8086800
I0609 05:04:35.926616 30564 layer_factory.hpp:77] Creating layer accuracy
I0609 05:04:35.926636 30564 net.cpp:84] Creating Layer accuracy
I0609 05:04:35.926646 30564 net.cpp:406] accuracy <- ip2_ip2_0_split_0
I0609 05:04:35.926658 30564 net.cpp:406] accuracy <- label_mnist_1_split_0
I0609 05:04:35.926676 30564 net.cpp:380] accuracy -> accuracy
I0609 05:04:35.926705 30564 net.cpp:122] Setting up accuracy
I0609 05:04:35.926719 30564 net.cpp:129] Top shape: (1)
I0609 05:04:35.926728 30564 net.cpp:137] Memory required for data: 8086804
I0609 05:04:35.926738 30564 layer_factory.hpp:77] Creating layer loss
I0609 05:04:35.926750 30564 net.cpp:84] Creating Layer loss
I0609 05:04:35.926759 30564 net.cpp:406] loss <- ip2_ip2_0_split_1
I0609 05:04:35.926771 30564 net.cpp:406] loss <- label_mnist_1_split_1
I0609 05:04:35.926812 30564 net.cpp:380] loss -> loss
I0609 05:04:35.926836 30564 layer_factory.hpp:77] Creating layer loss
I0609 05:04:35.927412 30564 net.cpp:122] Setting up loss
I0609 05:04:35.927430 30564 net.cpp:129] Top shape: (1)
I0609 05:04:35.927438 30564 net.cpp:132]     with loss weight 1
I0609 05:04:35.927458 30564 net.cpp:137] Memory required for data: 8086808
I0609 05:04:35.927469 30564 net.cpp:198] loss needs backward computation.
I0609 05:04:35.927481 30564 net.cpp:200] accuracy does not need backward computation.
I0609 05:04:35.927492 30564 net.cpp:198] ip2_ip2_0_split needs backward computation.
I0609 05:04:35.927503 30564 net.cpp:198] ip2 needs backward computation.
I0609 05:04:35.927512 30564 net.cpp:198] relu1 needs backward computation.
I0609 05:04:35.927521 30564 net.cpp:198] ip1 needs backward computation.
I0609 05:04:35.927531 30564 net.cpp:198] pool2 needs backward computation.
I0609 05:04:35.927541 30564 net.cpp:198] conv2 needs backward computation.
I0609 05:04:35.927551 30564 net.cpp:198] pool1 needs backward computation.
I0609 05:04:35.927561 30564 net.cpp:198] conv1 needs backward computation.
I0609 05:04:35.927572 30564 net.cpp:200] label_mnist_1_split does not need backward computation.
I0609 05:04:35.927582 30564 net.cpp:200] mnist does not need backward computation.
I0609 05:04:35.927592 30564 net.cpp:242] This network produces output accuracy
I0609 05:04:35.927600 30564 net.cpp:242] This network produces output loss
I0609 05:04:35.927633 30564 net.cpp:255] Network initialization done.
I0609 05:04:35.927724 30564 solver.cpp:56] Solver scaffolding done.
I0609 05:04:35.928316 30564 caffe.cpp:248] Starting Optimization
I0609 05:04:35.928331 30564 solver.cpp:272] Solving LeNet
I0609 05:04:35.928339 30564 solver.cpp:273] Learning Rate Policy: inv
I0609 05:04:35.930160 30564 solver.cpp:330] Iteration 0, Testing net (#0)
I0609 05:04:35.939982 30564 blocking_queue.cpp:49] Waiting for data
I0609 05:04:36.017017 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:36.017904 30564 solver.cpp:397]     Test net output #0: accuracy = 0.0928
I0609 05:04:36.017931 30564 solver.cpp:397]     Test net output #1: loss = 2.4162 (* 1 = 2.4162 loss)
I0609 05:04:36.021582 30564 solver.cpp:218] Iteration 0 (1.06118e+13 iter/s, 0.0931941s/100 iters), loss = 2.30339
I0609 05:04:36.021620 30564 solver.cpp:237]     Train net output #0: loss = 2.30339 (* 1 = 2.30339 loss)
I0609 05:04:36.021638 30564 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0609 05:04:36.184473 30564 solver.cpp:218] Iteration 100 (614.111 iter/s, 0.162837s/100 iters), loss = 0.232232
I0609 05:04:36.184522 30564 solver.cpp:237]     Train net output #0: loss = 0.232232 (* 1 = 0.232232 loss)
I0609 05:04:36.184533 30564 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I0609 05:04:36.337596 30564 solver.cpp:218] Iteration 200 (653.297 iter/s, 0.15307s/100 iters), loss = 0.164683
I0609 05:04:36.337640 30564 solver.cpp:237]     Train net output #0: loss = 0.164683 (* 1 = 0.164683 loss)
I0609 05:04:36.337651 30564 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I0609 05:04:36.485327 30564 solver.cpp:218] Iteration 300 (677.132 iter/s, 0.147682s/100 iters), loss = 0.181454
I0609 05:04:36.485368 30564 solver.cpp:237]     Train net output #0: loss = 0.181454 (* 1 = 0.181454 loss)
I0609 05:04:36.485379 30564 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I0609 05:04:36.631794 30564 solver.cpp:218] Iteration 400 (682.959 iter/s, 0.146422s/100 iters), loss = 0.104097
I0609 05:04:36.631837 30564 solver.cpp:237]     Train net output #0: loss = 0.104097 (* 1 = 0.104097 loss)
I0609 05:04:36.631855 30564 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I0609 05:04:36.785354 30564 solver.cpp:330] Iteration 500, Testing net (#0)
I0609 05:04:36.853998 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:36.854918 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9721
I0609 05:04:36.854946 30564 solver.cpp:397]     Test net output #1: loss = 0.089273 (* 1 = 0.089273 loss)
I0609 05:04:36.856415 30564 solver.cpp:218] Iteration 500 (445.323 iter/s, 0.224556s/100 iters), loss = 0.101664
I0609 05:04:36.856473 30564 solver.cpp:237]     Train net output #0: loss = 0.101664 (* 1 = 0.101664 loss)
I0609 05:04:36.856483 30564 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I0609 05:04:37.010967 30564 solver.cpp:218] Iteration 600 (647.303 iter/s, 0.154487s/100 iters), loss = 0.102078
I0609 05:04:37.011013 30564 solver.cpp:237]     Train net output #0: loss = 0.102078 (* 1 = 0.102078 loss)
I0609 05:04:37.011024 30564 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I0609 05:04:37.160631 30564 solver.cpp:218] Iteration 700 (668.404 iter/s, 0.14961s/100 iters), loss = 0.127544
I0609 05:04:37.160682 30564 solver.cpp:237]     Train net output #0: loss = 0.127544 (* 1 = 0.127544 loss)
I0609 05:04:37.160693 30564 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I0609 05:04:37.317946 30564 solver.cpp:218] Iteration 800 (635.889 iter/s, 0.15726s/100 iters), loss = 0.170443
I0609 05:04:37.317989 30564 solver.cpp:237]     Train net output #0: loss = 0.170442 (* 1 = 0.170442 loss)
I0609 05:04:37.317999 30564 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I0609 05:04:37.468475 30564 solver.cpp:218] Iteration 900 (664.586 iter/s, 0.15047s/100 iters), loss = 0.156516
I0609 05:04:37.468518 30564 solver.cpp:237]     Train net output #0: loss = 0.156516 (* 1 = 0.156516 loss)
I0609 05:04:37.468528 30564 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I0609 05:04:37.519281 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:37.618023 30564 solver.cpp:330] Iteration 1000, Testing net (#0)
I0609 05:04:37.682903 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:37.684476 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9832
I0609 05:04:37.684502 30564 solver.cpp:397]     Test net output #1: loss = 0.0537478 (* 1 = 0.0537478 loss)
I0609 05:04:37.685830 30564 solver.cpp:218] Iteration 1000 (460.176 iter/s, 0.217308s/100 iters), loss = 0.0950362
I0609 05:04:37.685863 30564 solver.cpp:237]     Train net output #0: loss = 0.0950362 (* 1 = 0.0950362 loss)
I0609 05:04:37.685871 30564 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I0609 05:04:37.835754 30564 solver.cpp:218] Iteration 1100 (667.178 iter/s, 0.149885s/100 iters), loss = 0.00652598
I0609 05:04:37.835798 30564 solver.cpp:237]     Train net output #0: loss = 0.00652591 (* 1 = 0.00652591 loss)
I0609 05:04:37.835808 30564 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I0609 05:04:37.985775 30564 solver.cpp:218] Iteration 1200 (666.792 iter/s, 0.149972s/100 iters), loss = 0.0243805
I0609 05:04:37.985829 30564 solver.cpp:237]     Train net output #0: loss = 0.0243805 (* 1 = 0.0243805 loss)
I0609 05:04:37.985841 30564 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I0609 05:04:38.136476 30564 solver.cpp:218] Iteration 1300 (663.829 iter/s, 0.150641s/100 iters), loss = 0.0242777
I0609 05:04:38.136520 30564 solver.cpp:237]     Train net output #0: loss = 0.0242777 (* 1 = 0.0242777 loss)
I0609 05:04:38.136530 30564 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I0609 05:04:38.288795 30564 solver.cpp:218] Iteration 1400 (656.738 iter/s, 0.152268s/100 iters), loss = 0.00703436
I0609 05:04:38.288839 30564 solver.cpp:237]     Train net output #0: loss = 0.00703437 (* 1 = 0.00703437 loss)
I0609 05:04:38.288851 30564 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I0609 05:04:38.436094 30564 solver.cpp:330] Iteration 1500, Testing net (#0)
I0609 05:04:38.504376 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:38.505303 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9852
I0609 05:04:38.505331 30564 solver.cpp:397]     Test net output #1: loss = 0.0462263 (* 1 = 0.0462263 loss)
I0609 05:04:38.506744 30564 solver.cpp:218] Iteration 1500 (458.923 iter/s, 0.217902s/100 iters), loss = 0.0755185
I0609 05:04:38.506778 30564 solver.cpp:237]     Train net output #0: loss = 0.0755185 (* 1 = 0.0755185 loss)
I0609 05:04:38.506786 30564 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I0609 05:04:38.654299 30564 solver.cpp:218] Iteration 1600 (677.892 iter/s, 0.147516s/100 iters), loss = 0.0744519
I0609 05:04:38.654377 30564 solver.cpp:237]     Train net output #0: loss = 0.074452 (* 1 = 0.074452 loss)
I0609 05:04:38.654391 30564 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I0609 05:04:38.805371 30564 solver.cpp:218] Iteration 1700 (662.294 iter/s, 0.15099s/100 iters), loss = 0.0248322
I0609 05:04:38.805414 30564 solver.cpp:237]     Train net output #0: loss = 0.0248322 (* 1 = 0.0248322 loss)
I0609 05:04:38.805424 30564 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I0609 05:04:38.955672 30564 solver.cpp:218] Iteration 1800 (665.543 iter/s, 0.150253s/100 iters), loss = 0.034136
I0609 05:04:38.955720 30564 solver.cpp:237]     Train net output #0: loss = 0.0341361 (* 1 = 0.0341361 loss)
I0609 05:04:38.955732 30564 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I0609 05:04:39.061254 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:39.105702 30564 solver.cpp:218] Iteration 1900 (666.767 iter/s, 0.149978s/100 iters), loss = 0.113209
I0609 05:04:39.105744 30564 solver.cpp:237]     Train net output #0: loss = 0.113209 (* 1 = 0.113209 loss)
I0609 05:04:39.105753 30564 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I0609 05:04:39.253742 30564 solver.cpp:330] Iteration 2000, Testing net (#0)
I0609 05:04:39.323099 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:39.324025 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9865
I0609 05:04:39.324051 30564 solver.cpp:397]     Test net output #1: loss = 0.0431666 (* 1 = 0.0431666 loss)
I0609 05:04:39.325513 30564 solver.cpp:218] Iteration 2000 (455.031 iter/s, 0.219765s/100 iters), loss = 0.0131887
I0609 05:04:39.325547 30564 solver.cpp:237]     Train net output #0: loss = 0.0131887 (* 1 = 0.0131887 loss)
I0609 05:04:39.325556 30564 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I0609 05:04:39.473804 30564 solver.cpp:218] Iteration 2100 (674.58 iter/s, 0.14824s/100 iters), loss = 0.0112928
I0609 05:04:39.473845 30564 solver.cpp:237]     Train net output #0: loss = 0.0112928 (* 1 = 0.0112928 loss)
I0609 05:04:39.473855 30564 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I0609 05:04:39.624363 30564 solver.cpp:218] Iteration 2200 (664.391 iter/s, 0.150514s/100 iters), loss = 0.0182663
I0609 05:04:39.624428 30564 solver.cpp:237]     Train net output #0: loss = 0.0182663 (* 1 = 0.0182663 loss)
I0609 05:04:39.624442 30564 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I0609 05:04:39.773738 30564 solver.cpp:218] Iteration 2300 (669.759 iter/s, 0.149307s/100 iters), loss = 0.0685879
I0609 05:04:39.773798 30564 solver.cpp:237]     Train net output #0: loss = 0.0685879 (* 1 = 0.0685879 loss)
I0609 05:04:39.773810 30564 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I0609 05:04:39.923262 30564 solver.cpp:218] Iteration 2400 (669.079 iter/s, 0.149459s/100 iters), loss = 0.0101178
I0609 05:04:39.923302 30564 solver.cpp:237]     Train net output #0: loss = 0.0101178 (* 1 = 0.0101178 loss)
I0609 05:04:39.923312 30564 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I0609 05:04:40.068500 30564 solver.cpp:330] Iteration 2500, Testing net (#0)
I0609 05:04:40.141831 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:40.142781 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9841
I0609 05:04:40.142818 30564 solver.cpp:397]     Test net output #1: loss = 0.0500213 (* 1 = 0.0500213 loss)
I0609 05:04:40.144322 30564 solver.cpp:218] Iteration 2500 (452.458 iter/s, 0.221015s/100 iters), loss = 0.0257367
I0609 05:04:40.144358 30564 solver.cpp:237]     Train net output #0: loss = 0.0257367 (* 1 = 0.0257367 loss)
I0609 05:04:40.144369 30564 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I0609 05:04:40.297297 30564 solver.cpp:218] Iteration 2600 (653.887 iter/s, 0.152932s/100 iters), loss = 0.0484303
I0609 05:04:40.297343 30564 solver.cpp:237]     Train net output #0: loss = 0.0484303 (* 1 = 0.0484303 loss)
I0609 05:04:40.297356 30564 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I0609 05:04:40.448793 30564 solver.cpp:218] Iteration 2700 (660.307 iter/s, 0.151445s/100 iters), loss = 0.065363
I0609 05:04:40.448840 30564 solver.cpp:237]     Train net output #0: loss = 0.065363 (* 1 = 0.065363 loss)
I0609 05:04:40.448853 30564 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I0609 05:04:40.594439 30564 solver.cpp:218] Iteration 2800 (686.838 iter/s, 0.145595s/100 iters), loss = 0.0048115
I0609 05:04:40.594485 30564 solver.cpp:237]     Train net output #0: loss = 0.00481153 (* 1 = 0.00481153 loss)
I0609 05:04:40.594494 30564 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I0609 05:04:40.606765 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:40.740840 30564 solver.cpp:218] Iteration 2900 (683.297 iter/s, 0.146349s/100 iters), loss = 0.0124049
I0609 05:04:40.740886 30564 solver.cpp:237]     Train net output #0: loss = 0.012405 (* 1 = 0.012405 loss)
I0609 05:04:40.740896 30564 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I0609 05:04:40.888317 30564 solver.cpp:330] Iteration 3000, Testing net (#0)
I0609 05:04:40.959041 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:40.961235 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9882
I0609 05:04:40.961264 30564 solver.cpp:397]     Test net output #1: loss = 0.0356071 (* 1 = 0.0356071 loss)
I0609 05:04:40.962790 30564 solver.cpp:218] Iteration 3000 (450.657 iter/s, 0.221898s/100 iters), loss = 0.00943767
I0609 05:04:40.962836 30564 solver.cpp:237]     Train net output #0: loss = 0.0094377 (* 1 = 0.0094377 loss)
I0609 05:04:40.962846 30564 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I0609 05:04:41.118700 30564 solver.cpp:218] Iteration 3100 (641.606 iter/s, 0.155859s/100 iters), loss = 0.0168101
I0609 05:04:41.118743 30564 solver.cpp:237]     Train net output #0: loss = 0.0168102 (* 1 = 0.0168102 loss)
I0609 05:04:41.118757 30564 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I0609 05:04:41.270362 30564 solver.cpp:218] Iteration 3200 (659.568 iter/s, 0.151614s/100 iters), loss = 0.00540582
I0609 05:04:41.270406 30564 solver.cpp:237]     Train net output #0: loss = 0.00540585 (* 1 = 0.00540585 loss)
I0609 05:04:41.270418 30564 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I0609 05:04:41.416893 30564 solver.cpp:218] Iteration 3300 (682.677 iter/s, 0.146482s/100 iters), loss = 0.0314329
I0609 05:04:41.416936 30564 solver.cpp:237]     Train net output #0: loss = 0.0314329 (* 1 = 0.0314329 loss)
I0609 05:04:41.416946 30564 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I0609 05:04:41.563727 30564 solver.cpp:218] Iteration 3400 (681.265 iter/s, 0.146786s/100 iters), loss = 0.0103265
I0609 05:04:41.563771 30564 solver.cpp:237]     Train net output #0: loss = 0.0103265 (* 1 = 0.0103265 loss)
I0609 05:04:41.563782 30564 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I0609 05:04:41.709156 30564 solver.cpp:330] Iteration 3500, Testing net (#0)
I0609 05:04:41.777843 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:41.778817 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9838
I0609 05:04:41.778846 30564 solver.cpp:397]     Test net output #1: loss = 0.046779 (* 1 = 0.046779 loss)
I0609 05:04:41.780266 30564 solver.cpp:218] Iteration 3500 (461.912 iter/s, 0.216491s/100 iters), loss = 0.00590023
I0609 05:04:41.780299 30564 solver.cpp:237]     Train net output #0: loss = 0.00590024 (* 1 = 0.00590024 loss)
I0609 05:04:41.780308 30564 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I0609 05:04:41.925325 30564 solver.cpp:218] Iteration 3600 (689.564 iter/s, 0.145019s/100 iters), loss = 0.0245254
I0609 05:04:41.925367 30564 solver.cpp:237]     Train net output #0: loss = 0.0245255 (* 1 = 0.0245255 loss)
I0609 05:04:41.925377 30564 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I0609 05:04:42.073053 30564 solver.cpp:218] Iteration 3700 (677.136 iter/s, 0.147681s/100 iters), loss = 0.0347294
I0609 05:04:42.073096 30564 solver.cpp:237]     Train net output #0: loss = 0.0347294 (* 1 = 0.0347294 loss)
I0609 05:04:42.073139 30564 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I0609 05:04:42.138592 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:42.217620 30564 solver.cpp:218] Iteration 3800 (691.941 iter/s, 0.144521s/100 iters), loss = 0.0128796
I0609 05:04:42.217664 30564 solver.cpp:237]     Train net output #0: loss = 0.0128796 (* 1 = 0.0128796 loss)
I0609 05:04:42.217674 30564 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I0609 05:04:42.362709 30564 solver.cpp:218] Iteration 3900 (689.458 iter/s, 0.145042s/100 iters), loss = 0.0327319
I0609 05:04:42.362749 30564 solver.cpp:237]     Train net output #0: loss = 0.0327319 (* 1 = 0.0327319 loss)
I0609 05:04:42.362761 30564 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I0609 05:04:42.505825 30564 solver.cpp:330] Iteration 4000, Testing net (#0)
I0609 05:04:42.570447 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:42.571334 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9894
I0609 05:04:42.571360 30564 solver.cpp:397]     Test net output #1: loss = 0.0322405 (* 1 = 0.0322405 loss)
I0609 05:04:42.572772 30564 solver.cpp:218] Iteration 4000 (476.148 iter/s, 0.210019s/100 iters), loss = 0.0160259
I0609 05:04:42.572804 30564 solver.cpp:237]     Train net output #0: loss = 0.0160259 (* 1 = 0.0160259 loss)
I0609 05:04:42.572814 30564 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I0609 05:04:42.717332 30564 solver.cpp:218] Iteration 4100 (691.933 iter/s, 0.144523s/100 iters), loss = 0.0394726
I0609 05:04:42.717372 30564 solver.cpp:237]     Train net output #0: loss = 0.0394726 (* 1 = 0.0394726 loss)
I0609 05:04:42.717383 30564 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I0609 05:04:42.864195 30564 solver.cpp:218] Iteration 4200 (681.127 iter/s, 0.146816s/100 iters), loss = 0.00721283
I0609 05:04:42.864243 30564 solver.cpp:237]     Train net output #0: loss = 0.00721287 (* 1 = 0.00721287 loss)
I0609 05:04:42.864258 30564 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I0609 05:04:43.018323 30564 solver.cpp:218] Iteration 4300 (649.036 iter/s, 0.154075s/100 iters), loss = 0.0473358
I0609 05:04:43.018368 30564 solver.cpp:237]     Train net output #0: loss = 0.0473358 (* 1 = 0.0473358 loss)
I0609 05:04:43.018379 30564 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I0609 05:04:43.167115 30564 solver.cpp:218] Iteration 4400 (672.305 iter/s, 0.148742s/100 iters), loss = 0.0219999
I0609 05:04:43.167158 30564 solver.cpp:237]     Train net output #0: loss = 0.022 (* 1 = 0.022 loss)
I0609 05:04:43.167168 30564 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I0609 05:04:43.314685 30564 solver.cpp:330] Iteration 4500, Testing net (#0)
I0609 05:04:43.382091 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:43.383803 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9876
I0609 05:04:43.383832 30564 solver.cpp:397]     Test net output #1: loss = 0.036222 (* 1 = 0.036222 loss)
I0609 05:04:43.385200 30564 solver.cpp:218] Iteration 4500 (458.637 iter/s, 0.218037s/100 iters), loss = 0.00538997
I0609 05:04:43.385234 30564 solver.cpp:237]     Train net output #0: loss = 0.00539003 (* 1 = 0.00539003 loss)
I0609 05:04:43.385244 30564 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I0609 05:04:43.529819 30564 solver.cpp:218] Iteration 4600 (691.673 iter/s, 0.144577s/100 iters), loss = 0.0150626
I0609 05:04:43.529861 30564 solver.cpp:237]     Train net output #0: loss = 0.0150626 (* 1 = 0.0150626 loss)
I0609 05:04:43.529871 30564 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I0609 05:04:43.651726 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:43.676147 30564 solver.cpp:218] Iteration 4700 (683.615 iter/s, 0.146281s/100 iters), loss = 0.00761069
I0609 05:04:43.676192 30564 solver.cpp:237]     Train net output #0: loss = 0.00761074 (* 1 = 0.00761074 loss)
I0609 05:04:43.676203 30564 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I0609 05:04:43.824180 30564 solver.cpp:218] Iteration 4800 (675.751 iter/s, 0.147984s/100 iters), loss = 0.0197815
I0609 05:04:43.824261 30564 solver.cpp:237]     Train net output #0: loss = 0.0197815 (* 1 = 0.0197815 loss)
I0609 05:04:43.824273 30564 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I0609 05:04:43.970055 30564 solver.cpp:218] Iteration 4900 (685.919 iter/s, 0.14579s/100 iters), loss = 0.00512233
I0609 05:04:43.970099 30564 solver.cpp:237]     Train net output #0: loss = 0.00512236 (* 1 = 0.00512236 loss)
I0609 05:04:43.970110 30564 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I0609 05:04:44.114235 30564 solver.cpp:447] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I0609 05:04:44.126389 30564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I0609 05:04:44.131116 30564 solver.cpp:330] Iteration 5000, Testing net (#0)
I0609 05:04:44.200286 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:44.201197 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9893
I0609 05:04:44.201226 30564 solver.cpp:397]     Test net output #1: loss = 0.0314111 (* 1 = 0.0314111 loss)
I0609 05:04:44.202643 30564 solver.cpp:218] Iteration 5000 (430.033 iter/s, 0.23254s/100 iters), loss = 0.0227622
I0609 05:04:44.202679 30564 solver.cpp:237]     Train net output #0: loss = 0.0227622 (* 1 = 0.0227622 loss)
I0609 05:04:44.202690 30564 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I0609 05:04:44.357929 30564 solver.cpp:218] Iteration 5100 (644.155 iter/s, 0.155242s/100 iters), loss = 0.02728
I0609 05:04:44.357977 30564 solver.cpp:237]     Train net output #0: loss = 0.0272801 (* 1 = 0.0272801 loss)
I0609 05:04:44.357988 30564 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I0609 05:04:44.510690 30564 solver.cpp:218] Iteration 5200 (654.842 iter/s, 0.152709s/100 iters), loss = 0.00812039
I0609 05:04:44.510737 30564 solver.cpp:237]     Train net output #0: loss = 0.00812043 (* 1 = 0.00812043 loss)
I0609 05:04:44.510748 30564 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I0609 05:04:44.661118 30564 solver.cpp:218] Iteration 5300 (665.005 iter/s, 0.150375s/100 iters), loss = 0.0028655
I0609 05:04:44.661170 30564 solver.cpp:237]     Train net output #0: loss = 0.00286555 (* 1 = 0.00286555 loss)
I0609 05:04:44.661182 30564 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I0609 05:04:44.819823 30564 solver.cpp:218] Iteration 5400 (630.326 iter/s, 0.158648s/100 iters), loss = 0.0076084
I0609 05:04:44.819869 30564 solver.cpp:237]     Train net output #0: loss = 0.00760845 (* 1 = 0.00760845 loss)
I0609 05:04:44.819880 30564 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I0609 05:04:44.974596 30564 solver.cpp:330] Iteration 5500, Testing net (#0)
I0609 05:04:45.041476 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:45.042505 30564 solver.cpp:397]     Test net output #0: accuracy = 0.989
I0609 05:04:45.042533 30564 solver.cpp:397]     Test net output #1: loss = 0.0322354 (* 1 = 0.0322354 loss)
I0609 05:04:45.043985 30564 solver.cpp:218] Iteration 5500 (446.201 iter/s, 0.224114s/100 iters), loss = 0.00945958
I0609 05:04:45.044020 30564 solver.cpp:237]     Train net output #0: loss = 0.00945963 (* 1 = 0.00945963 loss)
I0609 05:04:45.044029 30564 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I0609 05:04:45.199398 30564 solver.cpp:218] Iteration 5600 (643.618 iter/s, 0.155372s/100 iters), loss = 0.00149616
I0609 05:04:45.199441 30564 solver.cpp:237]     Train net output #0: loss = 0.00149622 (* 1 = 0.00149622 loss)
I0609 05:04:45.199455 30564 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I0609 05:04:45.231338 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:45.356606 30564 solver.cpp:218] Iteration 5700 (636.3 iter/s, 0.157159s/100 iters), loss = 0.00316102
I0609 05:04:45.356649 30564 solver.cpp:237]     Train net output #0: loss = 0.00316108 (* 1 = 0.00316108 loss)
I0609 05:04:45.356660 30564 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I0609 05:04:45.514323 30564 solver.cpp:218] Iteration 5800 (634.238 iter/s, 0.157669s/100 iters), loss = 0.030036
I0609 05:04:45.514395 30564 solver.cpp:237]     Train net output #0: loss = 0.0300361 (* 1 = 0.0300361 loss)
I0609 05:04:45.514407 30564 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I0609 05:04:45.671866 30564 solver.cpp:218] Iteration 5900 (635.048 iter/s, 0.157468s/100 iters), loss = 0.00416009
I0609 05:04:45.671911 30564 solver.cpp:237]     Train net output #0: loss = 0.00416014 (* 1 = 0.00416014 loss)
I0609 05:04:45.671923 30564 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I0609 05:04:45.827970 30564 solver.cpp:330] Iteration 6000, Testing net (#0)
I0609 05:04:45.893771 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:45.894615 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9906
I0609 05:04:45.894640 30564 solver.cpp:397]     Test net output #1: loss = 0.0279675 (* 1 = 0.0279675 loss)
I0609 05:04:45.896020 30564 solver.cpp:218] Iteration 6000 (446.214 iter/s, 0.224108s/100 iters), loss = 0.00367608
I0609 05:04:45.896054 30564 solver.cpp:237]     Train net output #0: loss = 0.00367614 (* 1 = 0.00367614 loss)
I0609 05:04:45.896062 30564 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I0609 05:04:46.052439 30564 solver.cpp:218] Iteration 6100 (639.476 iter/s, 0.156378s/100 iters), loss = 0.00383943
I0609 05:04:46.052486 30564 solver.cpp:237]     Train net output #0: loss = 0.00383948 (* 1 = 0.00383948 loss)
I0609 05:04:46.052498 30564 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I0609 05:04:46.210690 30564 solver.cpp:218] Iteration 6200 (632.115 iter/s, 0.158199s/100 iters), loss = 0.00936908
I0609 05:04:46.210734 30564 solver.cpp:237]     Train net output #0: loss = 0.00936912 (* 1 = 0.00936912 loss)
I0609 05:04:46.210747 30564 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I0609 05:04:46.369319 30564 solver.cpp:218] Iteration 6300 (630.597 iter/s, 0.15858s/100 iters), loss = 0.00878341
I0609 05:04:46.369362 30564 solver.cpp:237]     Train net output #0: loss = 0.00878346 (* 1 = 0.00878346 loss)
I0609 05:04:46.369374 30564 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I0609 05:04:46.527240 30564 solver.cpp:218] Iteration 6400 (633.428 iter/s, 0.157871s/100 iters), loss = 0.00549078
I0609 05:04:46.527287 30564 solver.cpp:237]     Train net output #0: loss = 0.00549083 (* 1 = 0.00549083 loss)
I0609 05:04:46.527298 30564 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I0609 05:04:46.671326 30564 solver.cpp:330] Iteration 6500, Testing net (#0)
I0609 05:04:46.741703 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:46.742633 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9905
I0609 05:04:46.742666 30564 solver.cpp:397]     Test net output #1: loss = 0.0300511 (* 1 = 0.0300511 loss)
I0609 05:04:46.744144 30564 solver.cpp:218] Iteration 6500 (461.141 iter/s, 0.216853s/100 iters), loss = 0.014025
I0609 05:04:46.744179 30564 solver.cpp:237]     Train net output #0: loss = 0.0140251 (* 1 = 0.0140251 loss)
I0609 05:04:46.744190 30564 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I0609 05:04:46.832515 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:46.896106 30564 solver.cpp:218] Iteration 6600 (658.247 iter/s, 0.151919s/100 iters), loss = 0.0248306
I0609 05:04:46.896152 30564 solver.cpp:237]     Train net output #0: loss = 0.0248307 (* 1 = 0.0248307 loss)
I0609 05:04:46.896162 30564 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I0609 05:04:47.048127 30564 solver.cpp:218] Iteration 6700 (658.022 iter/s, 0.151971s/100 iters), loss = 0.00967673
I0609 05:04:47.048177 30564 solver.cpp:237]     Train net output #0: loss = 0.00967681 (* 1 = 0.00967681 loss)
I0609 05:04:47.048187 30564 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I0609 05:04:47.204711 30564 solver.cpp:218] Iteration 6800 (638.859 iter/s, 0.156529s/100 iters), loss = 0.00268291
I0609 05:04:47.204761 30564 solver.cpp:237]     Train net output #0: loss = 0.00268299 (* 1 = 0.00268299 loss)
I0609 05:04:47.204773 30564 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I0609 05:04:47.361513 30564 solver.cpp:218] Iteration 6900 (637.965 iter/s, 0.156748s/100 iters), loss = 0.00853162
I0609 05:04:47.361559 30564 solver.cpp:237]     Train net output #0: loss = 0.00853169 (* 1 = 0.00853169 loss)
I0609 05:04:47.361570 30564 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I0609 05:04:47.518507 30564 solver.cpp:330] Iteration 7000, Testing net (#0)
I0609 05:04:47.584961 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:47.586555 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9892
I0609 05:04:47.586582 30564 solver.cpp:397]     Test net output #1: loss = 0.0315044 (* 1 = 0.0315044 loss)
I0609 05:04:47.587939 30564 solver.cpp:218] Iteration 7000 (441.742 iter/s, 0.226376s/100 iters), loss = 0.0056082
I0609 05:04:47.587971 30564 solver.cpp:237]     Train net output #0: loss = 0.00560828 (* 1 = 0.00560828 loss)
I0609 05:04:47.587980 30564 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I0609 05:04:47.737156 30564 solver.cpp:218] Iteration 7100 (670.345 iter/s, 0.149177s/100 iters), loss = 0.0106112
I0609 05:04:47.737200 30564 solver.cpp:237]     Train net output #0: loss = 0.0106113 (* 1 = 0.0106113 loss)
I0609 05:04:47.737210 30564 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I0609 05:04:47.887544 30564 solver.cpp:218] Iteration 7200 (665.162 iter/s, 0.150339s/100 iters), loss = 0.00421823
I0609 05:04:47.887588 30564 solver.cpp:237]     Train net output #0: loss = 0.0042183 (* 1 = 0.0042183 loss)
I0609 05:04:47.887598 30564 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I0609 05:04:48.037089 30564 solver.cpp:218] Iteration 7300 (668.911 iter/s, 0.149497s/100 iters), loss = 0.0255379
I0609 05:04:48.037133 30564 solver.cpp:237]     Train net output #0: loss = 0.025538 (* 1 = 0.025538 loss)
I0609 05:04:48.037143 30564 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I0609 05:04:48.185601 30564 solver.cpp:218] Iteration 7400 (673.566 iter/s, 0.148463s/100 iters), loss = 0.00529038
I0609 05:04:48.185647 30564 solver.cpp:237]     Train net output #0: loss = 0.00529046 (* 1 = 0.00529046 loss)
I0609 05:04:48.185657 30564 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I0609 05:04:48.326783 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:48.331887 30564 solver.cpp:330] Iteration 7500, Testing net (#0)
I0609 05:04:48.401569 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:48.402492 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9894
I0609 05:04:48.402518 30564 solver.cpp:397]     Test net output #1: loss = 0.0325209 (* 1 = 0.0325209 loss)
I0609 05:04:48.403945 30564 solver.cpp:218] Iteration 7500 (458.095 iter/s, 0.218295s/100 iters), loss = 0.00315401
I0609 05:04:48.403978 30564 solver.cpp:237]     Train net output #0: loss = 0.00315409 (* 1 = 0.00315409 loss)
I0609 05:04:48.403987 30564 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I0609 05:04:48.552517 30564 solver.cpp:218] Iteration 7600 (673.256 iter/s, 0.148532s/100 iters), loss = 0.00496713
I0609 05:04:48.552559 30564 solver.cpp:237]     Train net output #0: loss = 0.00496721 (* 1 = 0.00496721 loss)
I0609 05:04:48.552572 30564 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I0609 05:04:48.703407 30564 solver.cpp:218] Iteration 7700 (662.95 iter/s, 0.150841s/100 iters), loss = 0.0253828
I0609 05:04:48.703449 30564 solver.cpp:237]     Train net output #0: loss = 0.0253829 (* 1 = 0.0253829 loss)
I0609 05:04:48.703457 30564 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I0609 05:04:48.854137 30564 solver.cpp:218] Iteration 7800 (663.643 iter/s, 0.150683s/100 iters), loss = 0.00634025
I0609 05:04:48.854183 30564 solver.cpp:237]     Train net output #0: loss = 0.00634033 (* 1 = 0.00634033 loss)
I0609 05:04:48.854194 30564 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I0609 05:04:48.999815 30564 solver.cpp:218] Iteration 7900 (686.688 iter/s, 0.145627s/100 iters), loss = 0.00611262
I0609 05:04:48.999861 30564 solver.cpp:237]     Train net output #0: loss = 0.00611269 (* 1 = 0.00611269 loss)
I0609 05:04:48.999871 30564 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I0609 05:04:49.153719 30564 solver.cpp:330] Iteration 8000, Testing net (#0)
I0609 05:04:49.220371 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:49.221926 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9904
I0609 05:04:49.221954 30564 solver.cpp:397]     Test net output #1: loss = 0.029637 (* 1 = 0.029637 loss)
I0609 05:04:49.223335 30564 solver.cpp:218] Iteration 8000 (447.486 iter/s, 0.223471s/100 iters), loss = 0.00346176
I0609 05:04:49.223368 30564 solver.cpp:237]     Train net output #0: loss = 0.00346183 (* 1 = 0.00346183 loss)
I0609 05:04:49.223377 30564 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I0609 05:04:49.371529 30564 solver.cpp:218] Iteration 8100 (674.974 iter/s, 0.148154s/100 iters), loss = 0.0111498
I0609 05:04:49.371578 30564 solver.cpp:237]     Train net output #0: loss = 0.0111499 (* 1 = 0.0111499 loss)
I0609 05:04:49.371589 30564 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I0609 05:04:49.517194 30564 solver.cpp:218] Iteration 8200 (686.765 iter/s, 0.14561s/100 iters), loss = 0.0104535
I0609 05:04:49.517236 30564 solver.cpp:237]     Train net output #0: loss = 0.0104535 (* 1 = 0.0104535 loss)
I0609 05:04:49.517247 30564 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I0609 05:04:49.663300 30564 solver.cpp:218] Iteration 8300 (684.657 iter/s, 0.146059s/100 iters), loss = 0.0325362
I0609 05:04:49.663344 30564 solver.cpp:237]     Train net output #0: loss = 0.0325363 (* 1 = 0.0325363 loss)
I0609 05:04:49.663355 30564 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I0609 05:04:49.811247 30564 solver.cpp:218] Iteration 8400 (676.143 iter/s, 0.147898s/100 iters), loss = 0.00685269
I0609 05:04:49.811291 30564 solver.cpp:237]     Train net output #0: loss = 0.00685276 (* 1 = 0.00685276 loss)
I0609 05:04:49.811302 30564 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I0609 05:04:49.859911 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:49.955497 30564 solver.cpp:330] Iteration 8500, Testing net (#0)
I0609 05:04:50.024811 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:50.025738 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9904
I0609 05:04:50.025766 30564 solver.cpp:397]     Test net output #1: loss = 0.0291031 (* 1 = 0.0291031 loss)
I0609 05:04:50.027268 30564 solver.cpp:218] Iteration 8500 (463.022 iter/s, 0.215972s/100 iters), loss = 0.00780056
I0609 05:04:50.027304 30564 solver.cpp:237]     Train net output #0: loss = 0.00780063 (* 1 = 0.00780063 loss)
I0609 05:04:50.027314 30564 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I0609 05:04:50.179972 30564 solver.cpp:218] Iteration 8600 (655.048 iter/s, 0.152661s/100 iters), loss = 0.000528637
I0609 05:04:50.180021 30564 solver.cpp:237]     Train net output #0: loss = 0.000528716 (* 1 = 0.000528716 loss)
I0609 05:04:50.180032 30564 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I0609 05:04:50.334570 30564 solver.cpp:218] Iteration 8700 (647.056 iter/s, 0.154546s/100 iters), loss = 0.00228867
I0609 05:04:50.334615 30564 solver.cpp:237]     Train net output #0: loss = 0.00228875 (* 1 = 0.00228875 loss)
I0609 05:04:50.334625 30564 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I0609 05:04:50.488368 30564 solver.cpp:218] Iteration 8800 (650.411 iter/s, 0.153749s/100 iters), loss = 0.00206131
I0609 05:04:50.488432 30564 solver.cpp:237]     Train net output #0: loss = 0.00206138 (* 1 = 0.00206138 loss)
I0609 05:04:50.488443 30564 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I0609 05:04:50.632947 30564 solver.cpp:218] Iteration 8900 (691.991 iter/s, 0.14451s/100 iters), loss = 0.00040962
I0609 05:04:50.632990 30564 solver.cpp:237]     Train net output #0: loss = 0.000409695 (* 1 = 0.000409695 loss)
I0609 05:04:50.633002 30564 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I0609 05:04:50.776790 30564 solver.cpp:330] Iteration 9000, Testing net (#0)
I0609 05:04:50.851299 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:50.852958 30564 solver.cpp:397]     Test net output #0: accuracy = 0.99
I0609 05:04:50.852988 30564 solver.cpp:397]     Test net output #1: loss = 0.0306701 (* 1 = 0.0306701 loss)
I0609 05:04:50.854435 30564 solver.cpp:218] Iteration 9000 (451.588 iter/s, 0.221441s/100 iters), loss = 0.0148869
I0609 05:04:50.854470 30564 solver.cpp:237]     Train net output #0: loss = 0.014887 (* 1 = 0.014887 loss)
I0609 05:04:50.854480 30564 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I0609 05:04:51.007990 30564 solver.cpp:218] Iteration 9100 (651.41 iter/s, 0.153513s/100 iters), loss = 0.00712426
I0609 05:04:51.008034 30564 solver.cpp:237]     Train net output #0: loss = 0.00712433 (* 1 = 0.00712433 loss)
I0609 05:04:51.008044 30564 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I0609 05:04:51.161370 30564 solver.cpp:218] Iteration 9200 (652.187 iter/s, 0.15333s/100 iters), loss = 0.00235374
I0609 05:04:51.161415 30564 solver.cpp:237]     Train net output #0: loss = 0.00235381 (* 1 = 0.00235381 loss)
I0609 05:04:51.161427 30564 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I0609 05:04:51.314944 30564 solver.cpp:218] Iteration 9300 (651.37 iter/s, 0.153523s/100 iters), loss = 0.0069264
I0609 05:04:51.314990 30564 solver.cpp:237]     Train net output #0: loss = 0.00692648 (* 1 = 0.00692648 loss)
I0609 05:04:51.315001 30564 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I0609 05:04:51.425446 30576 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:51.471948 30564 solver.cpp:218] Iteration 9400 (637.134 iter/s, 0.156953s/100 iters), loss = 0.0421853
I0609 05:04:51.471995 30564 solver.cpp:237]     Train net output #0: loss = 0.0421854 (* 1 = 0.0421854 loss)
I0609 05:04:51.472005 30564 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I0609 05:04:51.625864 30564 solver.cpp:330] Iteration 9500, Testing net (#0)
I0609 05:04:51.693032 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:51.693977 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9889
I0609 05:04:51.694008 30564 solver.cpp:397]     Test net output #1: loss = 0.0343711 (* 1 = 0.0343711 loss)
I0609 05:04:51.695466 30564 solver.cpp:218] Iteration 9500 (447.492 iter/s, 0.223468s/100 iters), loss = 0.00322924
I0609 05:04:51.695502 30564 solver.cpp:237]     Train net output #0: loss = 0.00322932 (* 1 = 0.00322932 loss)
I0609 05:04:51.695510 30564 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I0609 05:04:51.848738 30564 solver.cpp:218] Iteration 9600 (652.617 iter/s, 0.153229s/100 iters), loss = 0.00399297
I0609 05:04:51.848784 30564 solver.cpp:237]     Train net output #0: loss = 0.00399304 (* 1 = 0.00399304 loss)
I0609 05:04:51.848795 30564 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I0609 05:04:52.005273 30564 solver.cpp:218] Iteration 9700 (639.044 iter/s, 0.156484s/100 iters), loss = 0.00346188
I0609 05:04:52.005319 30564 solver.cpp:237]     Train net output #0: loss = 0.00346195 (* 1 = 0.00346195 loss)
I0609 05:04:52.005329 30564 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I0609 05:04:52.161708 30564 solver.cpp:218] Iteration 9800 (639.452 iter/s, 0.156384s/100 iters), loss = 0.0105025
I0609 05:04:52.161753 30564 solver.cpp:237]     Train net output #0: loss = 0.0105026 (* 1 = 0.0105026 loss)
I0609 05:04:52.161764 30564 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I0609 05:04:52.316066 30564 solver.cpp:218] Iteration 9900 (648.057 iter/s, 0.154307s/100 iters), loss = 0.00493538
I0609 05:04:52.316113 30564 solver.cpp:237]     Train net output #0: loss = 0.00493546 (* 1 = 0.00493546 loss)
I0609 05:04:52.316123 30564 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I0609 05:04:52.470319 30564 solver.cpp:447] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I0609 05:04:52.479295 30564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I0609 05:04:52.484874 30564 solver.cpp:310] Iteration 10000, loss = 0.00251056
I0609 05:04:52.484899 30564 solver.cpp:330] Iteration 10000, Testing net (#0)
I0609 05:04:52.549607 30581 data_layer.cpp:73] Restarting data prefetching from start.
I0609 05:04:52.551172 30564 solver.cpp:397]     Test net output #0: accuracy = 0.9905
I0609 05:04:52.551199 30564 solver.cpp:397]     Test net output #1: loss = 0.0303988 (* 1 = 0.0303988 loss)
I0609 05:04:52.551208 30564 solver.cpp:315] Optimization Done.
I0609 05:04:52.551215 30564 caffe.cpp:259] Optimization Done.
